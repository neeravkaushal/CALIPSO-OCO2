{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell  #---- Output all jupyter lab inputs instead of the last one\n",
    "from IPython.display import Markdown, display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"             \n",
    "import glob #---------------------------------------------------- To read the files or folders in a system directory\n",
    "from netCDF4 import Dataset #------------------------------------ To read nc , nc4 and hdf4 files\n",
    "import numpy as np\n",
    "import datetime\n",
    "import h5py #---------------------------------------------------- To read hdf5 files\n",
    "from scipy import spatial #-------------------------------------- To extract the values and indices of k nearest neighbors\n",
    "import pandas as pd\n",
    "from ast import literal_eval #----------------------------------- For literal evaluation of a string to extract python objects\n",
    "from pyproj import Proj, transform #----------------------------- To interconvert different projections\n",
    "import warnings #------------------------------------------------ To suppress warnings\n",
    "from photutils.utils import ShepardIDWInterpolator as idw #------ To use Shepard's Inverse Distance Weighing Interpolation tool\n",
    "import re #------------------------------------------------------ To replace characters in a string\n",
    "import time as tttt\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pyresample\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter('ignore')\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_proj  = Proj('+proj=sinu +R=6371007.181 +nadgrids=@null +wktext') #------ Specify input projection\n",
    "out_proj = Proj(init='epsg:4326') #----------------------------------------- Specify output projection\n",
    "\n",
    "def Times(x): #------------------------------------------Extract Time from sounding ID. NOTE the time format is HH:MM:SSSS\n",
    "    y   = str(x)\n",
    "    yy  = y[8:]\n",
    "    yyy = '{}:{}:{}'.format(yy[:2], yy[2:4], yy[4:])\n",
    "    return yyy\n",
    "\n",
    "hours = [0, 3000000, 6000000, 9000000, 12000000, 15000000, 18000000, 21000000, 23595900]\n",
    "def f(x): #---------------------------------------------Extract the hour interval of sif time (which  is in seconds)\n",
    "    for i in range(len(hours)):\n",
    "        if (x>hours[i]) and (x<hours[i+1]):\n",
    "            lb = hours[i]\n",
    "            ub = hours[i+1]\n",
    "            return lb,ub\n",
    "            break\n",
    "\n",
    "def format_time(t): #----------------------------------- Format the time into HH:MM:SSSS for the raw format HH:MM:SSSSSSSS\n",
    "    s = t\n",
    "    return s[:-4]\n",
    "\n",
    "def nn(latitude_list,longitude_list,target): #---------- Find the index of nearest neighbor (NOTE: absolute difference)\n",
    "    target_lat, target_lon = target[1], target[0]\n",
    "    d = [abs(latitude-target_lat) + abs(longitude-target_lon) for latitude,longitude in zip(latitude_list,longitude_list)]\n",
    "    return np.argmin(d)\n",
    "\n",
    "data = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3)\n",
    "def tile_finder(Lat,Lon): #----------------------------- Find modis tile numbers in which the argument lat,lon lies\n",
    "    in_tile = False\n",
    "    i = 0\n",
    "    while(not in_tile):\n",
    "        in_tile = Lat >= data[i, 4] and Lat <= data[i, 5] and Lon >= data[i, 2] and Lon <= data[i, 3]\n",
    "        i += 1\n",
    "    V = str(int(data[i-1, 0])).zfill(2)\n",
    "    H = str(int(data[i-1, 1])).zfill(2)\n",
    "    return H,V\n",
    "\n",
    "def extract_pixel_coordinates(ULx,Uly,LRx,LRy,shape):\n",
    "    x        = np.linspace(ULx, LRx, shape[0], endpoint=False) + abs((ULx-LRx)/(2*shape[0]))\n",
    "    y        = np.linspace(ULy, LRy, shape[0], endpoint=False) - abs((ULy-LRy)/(2*shape[0]))\n",
    "    xx, yy   = np.meshgrid(x,y)\n",
    "    plon, plat = transform(in_proj, out_proj, xx, yy)\n",
    "    #mlon, mlat = plon[0], np.array([i[0] for i in plat])\n",
    "    plon       = plon.flatten()\n",
    "    plat       = plat.flatten()\n",
    "    return plon, plat#, mlon, mlat\n",
    "\n",
    "def temporal_interpolation(time1,val1,time2,val2,timeX):\n",
    "    df    = pd.DataFrame( [(time1, val1) , (time2, val2)] , columns=['Times','Values'] ) \n",
    "    df    = df.set_index('Times')\n",
    "    df    = pd.Series(df['Values'], index=df.index)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    inter = df.resample('S').interpolate(method='linear')\n",
    "    valX  = inter.loc[timeX]\n",
    "    return valX\n",
    "\n",
    "sif_file_list     = sorted(glob.glob('OCO2_sif/*.nc4'))    #--------------------------------------------- List of all OCO2 files\n",
    "calipso_file_list = sorted(glob.glob('OCO2_calipso/*.h5')) #--------------------------------------------- List of all OCO2-CALIPSO files\n",
    "fpar_file_list    = sorted(glob.glob('MCD15A3H/*.hdf'))    \n",
    "par_folder_list   = sorted(glob.glob('MCD18A2/*'))\n",
    "ref_folder_list   = sorted(glob.glob('MCD43A4/*'))\n",
    "data              = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3) #------ File having tile numbers and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**For 2018-05-01, there are 12081 sif footprints scattered over 46 tiles.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Processing shape :  2400 x 2400\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**14.973532299200693 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  1200 x 1200\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.797980256875356 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  800 x 800\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.5795952995618185 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  600 x 600\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.4875385244687398 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  400 x 400\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.4164480288823447 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  200 x 200\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.3592254638671875 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**For 2018-05-02, there are 15237 sif footprints scattered over 49 tiles.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Processing shape :  2400 x 2400\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**16.390267904599508 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  1200 x 1200\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.9385984659194946 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  800 x 800\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.6881709496180217 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  600 x 600\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.5945033351580302 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  400 x 400\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.5174828926722208 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  200 x 200\n",
      "REF Processing Started...\n",
      "\n",
      "h07v05 h08v04 h09v03 h11v02 h11v07 h11v08 h11v09 h12v03 h12v04 h12v09 h12v10 h12v11 h13v02 h13v03 h14v01 h16v02 h16v06 h16v07 h17v00 h18v00 h18v01 h18v02 h18v03 h19v01 h19v03 h19v04 h20v02 h20v05 h20v06 h21v02 h21v03 h21v07 h21v08 h21v09 h21v10 h22v02 h22v04 h23v03 h24v03 h24v06 h25v04 h25v06 h25v07 h26v04 h28v12 h29v12 h30v11 h31v09 h31v10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.429475200176239 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**For 2018-05-03, there are 17618 sif footprints scattered over 53 tiles.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Processing shape :  2400 x 2400\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**17.33989371061325 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  1200 x 1200\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2.1336095571517943 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  800 x 800\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.8153033137321473 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  600 x 600\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.6826311031977335 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  400 x 400\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.5997619350751242 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shape :  200 x 200\n",
      "REF Processing Started...\n",
      "\n",
      "h07v07 h08v05 h08v06 h08v07 h09v04 h10v03 h11v02 h12v02 h13v03 h13v04 h13v09 h13v10 h13v11 h14v01 h14v02 h14v03 h15v01 h16v00 h16v01 h16v02 h17v00 h17v01 h17v04 h17v05 h17v06 h17v07 h17v08 h18v00 h18v01 h18v02 h19v01 h19v02 h19v03 h20v01 h20v02 h20v04 h21v06 h22v02 h22v03 h22v06 h22v07 h22v08 h22v11 h23v04 h24v03 h24v05 h26v04 h26v06 h27v07 h27v08 h27v09 h31v07 h32v09 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1.5701183438301087 minutes**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sif_file in sif_file_list: #---------------------------------------------------------------------------Read one sif file at a time\n",
    "    sif_date        = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%Y-%m-%d\") #-----Extract sif date\n",
    "    sif_julian_day  = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%j\") #-----------Extract sif julian day\n",
    "    sif             = Dataset(sif_file, mode='r') #-----------------------------------------------------------Open sif file\n",
    "    calipso_df_list = [] #------------------------------------------------------------------------------------Create an empty list\n",
    "    for calipso_file in calipso_file_list: #------------------------------------------------------------------Loop through all calipso files\n",
    "        calipso_date      = datetime.datetime.strptime(calipso_file.split('_')[5], '%y%m%d').strftime(\"%Y-%m-%d\")\n",
    "        if calipso_date  == sif_date: #----------------------------------------------------------------------------If calipso date matches sif date,\n",
    "            calipso       = h5py.File(calipso_file, mode='r') #----------------------------------------------------open the calipso file\n",
    "            calipso_ID    = calipso['OCO2_sounding_id'                                           ][:]\n",
    "            calipso_dist  = calipso['matchup_distance_km'                                        ][:]\n",
    "            calipso_index = calipso['matchup_Xindex'                                             ][:]\n",
    "            calipso_dfs   = pd.DataFrame({'sounding_id':calipso_ID.flatten(),'Xindex':calipso_index.flatten(),'Xdistance':calipso_dist.flatten()}) #-----Create dataframe with variables\n",
    "            calipso_dfs[calipso_dfs.Xindex==-999.0] = np.nan #------- Replace missing values with nan\n",
    "            calipso_dfs.dropna(inplace=True) #----------------------- Drop missing values of Xindex\n",
    "            calipso_dfs[calipso_dfs.Xdistance>=2.0] = np.nan\n",
    "            calipso_dfs.dropna(inplace=True)\n",
    "            calipso_df_list.append(calipso_dfs) #-------------------- Add all calipso dataframes into a list\n",
    "    calipso_df                     = pd.concat(calipso_df_list, ignore_index = True).drop_duplicates() #---------Create a final calipso dataframe for a day\n",
    "\n",
    "    cloud_albedo                   = sif.groups['Cloud'].variables['albedo'                 ][:].flatten() #--------Read sif variables and flatten them\n",
    "    cloud_flag                     = sif.groups['Cloud'].variables['cloud_flag'             ][:].flatten()\n",
    "    cloud_co2_ratio                = sif.groups['Cloud'].variables['co2_ratio'              ][:].flatten()\n",
    "    cloud_delta_surface_pressure   = sif.groups['Cloud'].variables['delta_surface_pressure' ][:].flatten()\n",
    "    cloud_o2_ratio                 = sif.groups['Cloud'].variables['o2_ratio'               ][:].flatten()\n",
    "    vapor_pressure_deficit         = sif.groups['Meteo'].variables['vapor_pressure_deficit' ][:].flatten()\n",
    "    temperature_2m                 = sif.groups['Meteo'].variables['2m_temperature'         ][:].flatten()\n",
    "    temperature_skin               = sif.groups['Meteo'].variables['skin_temperature'       ][:].flatten()\n",
    "    specific_humidity              = sif.groups['Meteo'].variables['specific_humidity'      ][:].flatten()\n",
    "    surface_pressure               = sif.groups['Meteo'].variables['surface_pressure'       ][:].flatten()\n",
    "    wind_speed                     = sif.groups['Meteo'].variables['wind_speed'             ][:].flatten()\n",
    "    continuum_radiance_757nm       = sif.variables         ['continuum_radiance_757nm'      ][:].flatten()\n",
    "    continuum_radiance_771nm       = sif.variables         ['continuum_radiance_771nm'      ][:].flatten()\n",
    "    daily_correction_factor        = sif.variables         ['daily_correction_factor'       ][:].flatten()\n",
    "    footprint                      = sif.variables         ['footprint'                     ][:].flatten()\n",
    "    IGBP_index                     = sif.variables         ['IGBP_index'                    ][:].flatten()\n",
    "    latitude                       = sif.variables         ['latitude'                      ][:].flatten()\n",
    "    longitude                      = sif.variables         ['longitude'                     ][:].flatten()\n",
    "    measurement_mode               = sif.variables         ['measurement_mode'              ][:].flatten()\n",
    "    orbit_number                   = sif.variables         ['orbit_number'                  ][:].flatten()\n",
    "    reduced_chi2_757nm             = sif.variables         ['reduced_chi2_757nm'            ][:].flatten()\n",
    "    reduced_chi2_771nm             = sif.variables         ['reduced_chi2_771nm'            ][:].flatten()\n",
    "    sensor_azimuth_angle           = sif.variables         ['sensor_azimuth_angle'          ][:].flatten()\n",
    "    sensor_zenith_angle            = sif.variables         ['sensor_zenith_angle'           ][:].flatten()\n",
    "    SIF_757nm                      = sif.variables         ['SIF_757nm'                     ][:].flatten() #----------Use this condition for next block\n",
    "    SIF_757nm_relative             = sif.variables         ['SIF_757nm_relative'            ][:].flatten()\n",
    "    SIF_757nm_uncert               = sif.variables         ['SIF_757nm_uncert'              ][:].flatten()\n",
    "    SIF_771nm                      = sif.variables         ['SIF_771nm'                     ][:].flatten()\n",
    "    SIF_771nm_relative             = sif.variables         ['SIF_771nm_relative'            ][:].flatten()\n",
    "    SIF_771nm_uncert               = sif.variables         ['SIF_771nm_uncert'              ][:].flatten()\n",
    "    solar_azimuth_angle            = sif.variables         ['solar_azimuth_angle'           ][:].flatten()\n",
    "    solar_zenith_angle             = sif.variables         ['solar_zenith_angle'            ][:].flatten()\n",
    "    sounding_id                    = sif.variables         ['sounding_id'                   ][:].flatten()\n",
    "    surface_altitude               = sif.variables         ['surface_altitude'              ][:].flatten()\n",
    "    time                           = sif.variables         ['time'                          ][:].flatten()\n",
    "    uncorrected_SIF_757nm          = sif.variables         ['uncorrected_SIF_757nm'         ][:].flatten()\n",
    "    uncorrected_SIF_757nm_relative = sif.variables         ['uncorrected_SIF_757nm_relative'][:].flatten()\n",
    "    uncorrected_SIF_771nm          = sif.variables         ['uncorrected_SIF_771nm'         ][:].flatten()\n",
    "    uncorrected_SIF_771nm_relative = sif.variables         ['uncorrected_SIF_771nm_relative'][:].flatten()\n",
    "      \n",
    "    sif_rows  = [(SIF_757nm[i], cloud_albedo[i], cloud_flag[i], cloud_co2_ratio[i], cloud_delta_surface_pressure[i], cloud_o2_ratio[i], vapor_pressure_deficit[i],\n",
    "                  temperature_2m[i], temperature_skin[i], specific_humidity[i], surface_pressure[i], wind_speed[i], continuum_radiance_757nm[i],\n",
    "                  continuum_radiance_771nm[i],daily_correction_factor[i], footprint[i], IGBP_index[i], latitude[i], longitude[i], measurement_mode[i],\n",
    "                  orbit_number[i], reduced_chi2_757nm[i],reduced_chi2_771nm[i], sensor_azimuth_angle[i], sensor_zenith_angle[i], SIF_757nm_relative[i],\n",
    "                  SIF_757nm_uncert[i], SIF_771nm[i],SIF_771nm_relative[i], SIF_771nm_uncert[i], solar_azimuth_angle[i], solar_zenith_angle[i], sounding_id[i],\n",
    "                  surface_altitude[i], time[i], uncorrected_SIF_757nm[i], uncorrected_SIF_757nm_relative[i], uncorrected_SIF_771nm[i], uncorrected_SIF_771nm_relative[i])\n",
    "                  for i in range(0,len(sounding_id))]\n",
    "    \n",
    "    column_labels = ['SIF_757nm', 'cloud_albedo', 'cloud_flag', 'cloud_co2_ratio', 'cloud_delta_surface_pressure', 'cloud_o2_ratio', 'vapor_pressure_deficit',\n",
    "                     'temperature_2m', 'temperature_skin', 'specific_humidity', 'surface_pressure', 'wind_speed', 'continuum_radiance_757nm',\n",
    "                     'continuum_radiance_771nm','daily_correction_factor', 'footprint', 'IGBP_index', 'latitude', 'longitude', 'measurement_mode',\n",
    "                     'orbit_number', 'reduced_chi2_757nm','reduced_chi2_771nm', 'sensor_azimuth_angle', 'sensor_zenith_angle',\n",
    "                     'SIF_757nm_relative', 'SIF_757nm_uncert', 'SIF_771nm','SIF_771nm_relative', 'SIF_771nm_uncert', 'solar_azimuth_angle', 'solar_zenith_angle',\n",
    "                     'sounding_id', 'surface_altitude', 'time','uncorrected_SIF_757nm', 'uncorrected_SIF_757nm_relative', 'uncorrected_SIF_771nm',\n",
    "                     'uncorrected_SIF_771nm_relative']\n",
    "     \n",
    "    sif_df                         = pd.DataFrame(sif_rows,columns = column_labels) #-------- Create sif variables' dataframe\n",
    "    calipso_sif_merger             = pd.merge(sif_df, calipso_df, on = ['sounding_id'], how = 'inner') #--------Merge sif and calipso on sounding _id\n",
    "    calipso_sif_merger['Date']     = calipso_sif_merger['sounding_id'].map(lambda x: '-'.join([str(x)[:4],str(x)[4:6],str(x)[6:]])[:10]) #-----Create new date column\n",
    "    calipso_sif_merger['SIF_Time'] = calipso_sif_merger['sounding_id'].map(lambda x: Times(x))  #----------------------------------------------Create new time column\n",
    "    calipso_sif_merger['tile_h'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[0], axis=1) #------Create new horizontal tile column\n",
    "    calipso_sif_merger['tile_v'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[1], axis=1) #------Create new vertical tile column\n",
    "    calipso_sif_merger             = calipso_sif_merger.dropna(how='any')\n",
    "\n",
    "    grp         = calipso_sif_merger.groupby(['tile_h', 'tile_v']).agg(lambda x: list(x))  #----Group sif-calipso merger(from now on called SIF*) by tile id\n",
    "    grp         = grp.reset_index() #-----------------------------------------------------------Reset indices\n",
    "    l_ungrouped = len(calipso_sif_merger)\n",
    "    l_grouped   = len(grp)\n",
    "    df          = grp.copy() #--------make a copy of the grouped file\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    printmd('**For {}, there are {} sif footprints scattered over {} tiles.**'.format(sif_date, l_ungrouped, l_grouped))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------')  \n",
    "\n",
    "\n",
    "    shapes              = [(2400,2400)]#, (1200,1200), (800,800), (600,600), (400,400), (200,200)]\n",
    "    for shape2 in shapes:\n",
    "        print('Processing shape : ', shape2[0],'x',shape2[1])\n",
    "        a                   = tttt.time()\n",
    "        print('REF Processing Started...\\n')\n",
    "        Each_Ref_Tile_Data  = []\n",
    "        for index,h_sif,v_sif,sif_lon,sif_lat,sif_time,sif_sid in zip(df.index,df['tile_h'],df['tile_v'],df['longitude'],df['latitude'],df['SIF_Time'],df['sounding_id']):\n",
    "            print('h{}v{}'.format(h_sif,v_sif), flush = True, sep=',', end=' ')\n",
    "\n",
    "            for folder_number in range(len(ref_folder_list)):\n",
    "                ref_julian_day    = ref_folder_list[folder_number].split('/')[1]\n",
    "\n",
    "                if sif_julian_day == ref_julian_day:\n",
    "                    ref_file_list = glob.glob(ref_folder_list[folder_number]+'/*.hdf')\n",
    "\n",
    "                    for num3,ref_file in enumerate(ref_file_list):\n",
    "                        h_ref = ref_file.split('.')[2][1:3]\n",
    "                        v_ref = ref_file.split('.')[2][4:6]\n",
    "\n",
    "                        if (h_ref==h_sif) and (v_ref==v_sif):\n",
    "                            ref              = Dataset(ref_file, mode='r')\n",
    "                            nrb1             = ref.variables['Nadir_Reflectance_Band1'][:]\n",
    "                            fv1              = ref.variables['Nadir_Reflectance_Band1']._FillValue\n",
    "                            nrb2             = ref.variables['Nadir_Reflectance_Band2'][:]\n",
    "                            fv2              = ref.variables['Nadir_Reflectance_Band2']._FillValue\n",
    "                            struct           = getattr(ref, 'StructMetadata.0')\n",
    "                            struct1          = struct[struct.find('UpperLeftPointMtrs'): struct.find('LowerRightMtrs')][19:-3]\n",
    "                            struct2          = struct[struct.find('LowerRightMtrs')    : struct.find('Projection')    ][15:-3]\n",
    "                            ULx, ULy         = literal_eval(struct1)\n",
    "                            LRx, LRy         = literal_eval(struct2)\n",
    "                            \n",
    "                            ref_lon,ref_lat,ref_mlon,ref_mlat = extract_pixel_coordinates(ULx,ULy,LRx,LRy,(2400,2400))\n",
    "                            \n",
    "                            \n",
    "                            t_lat                    = np.linspace(ref_mlat[0], ref_mlat[-1], shape2[0], endpoint=True)\n",
    "                            t_lon                    = np.linspace(ref_mlon[0], ref_mlon[-1], shape2[1], endpoint=True)                         \n",
    "\n",
    "                            source_lons, source_lats = np.meshgrid(ref_mlon, ref_mlat)\n",
    "                            dest_lons, dest_lats     = np.meshgrid(t_lon, t_lat)\n",
    "                            \n",
    "                            orig_def                 = pyresample.geometry.SwathDefinition(lons=source_lons, lats=source_lats)\n",
    "                            targ_def                 = pyresample.geometry.SwathDefinition(lons=dest_lons  , lats=dest_lats  )\n",
    "                            \n",
    "                            nrb01                    = nrb1.flatten()\n",
    "                            wf                       = lambda r: 1/r**2\n",
    "                            \n",
    "                            if shape2 != (2400,2400):\n",
    "                                interp_nrb1    = pyresample.kd_tree.resample_custom(orig_def, nrb1, targ_def, radius_of_influence=500000, neighbours=4, weight_funcs=wf, fill_value=float(fv1))\n",
    "                                #interp_nrb2    = pyresample.kd_tree.resample_custom(orig_def, nrb2, targ_def, radius_of_influence=500000, neighbours=4, weight_funcs=wf, fill_value=float(fv2))\n",
    "                                tree           = spatial.KDTree( list(  zip(t_lon.flatten(), t_lat.flatten()) ))\n",
    "                                for sub in range(len(sif_time)):\n",
    "                                    target     = (sif_lat[sub] , sif_lon[sub])\n",
    "                                    ind        = tree.query([(sif_lon[sub],sif_lat[sub])], k=1)[1][0]\n",
    "                                    Each_Ref_Tile_Data.append((sif_sid[sub], sif_lat[sub],sif_lon[sub],nrb01[ind]))\n",
    "                            else:\n",
    "                                tree           = spatial.KDTree( list(  zip(ref_lon.flatten(), ref_lat.flatten()) ))\n",
    "                                for sub in range(len(sif_time)):\n",
    "                                    target     = (sif_lat[sub] , sif_lon[sub])\n",
    "                                    ind        = tree.query([(sif_lon[sub],sif_lat[sub])], k=1)[1][0]\n",
    "                                    Each_Ref_Tile_Data.append((sif_sid[sub], sif_lat[sub],sif_lon[sub],nrb01[ind]))\n",
    "\n",
    "\n",
    "        DG = pd.DataFrame(np.array(Each_Ref_Tile_Data),columns=['sounding_id','latitude','longitude','nrb1'])\n",
    "        DG.to_csv('Optimization/{}_ref_{}.csv'.format(sif_date,shape2[0]),index=False)\n",
    "        print('\\n')\n",
    "        b  = tttt.time()\n",
    "        printmd('**{} minutes**'.format((b-a)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                            \n",
    "                            if shape2 == (2400,2400):\n",
    "                                ref_lonx, ref_latx = ref_lon, ref_lat\n",
    "                                ref_lon , ref_lat  = ref_lonx[(nrb1x.mask==False) & (nrb2x.mask==False)] , ref_latx[(nrb1x.mask==False) & (nrb2x.mask==False)]\n",
    "                                \n",
    "                            tree             = spatial.KDTree( list(  zip(ref_lon, ref_lat) ))\n",
    "                            \n",
    "                            for sub in range(len(sif_time)):\n",
    "                                target         = (sif_lat[sub] , sif_lon[sub])\n",
    "                                neigh10        = tree.query([(sif_lon[sub], sif_lat[sub])], k=4)[1][0] #---Find k=3 nearest spatial neighbors indices at target\n",
    "                                #neigh10\n",
    "                                lon_for_idw    = [ref_lon[i] for i in neigh10] #----------------------------Extract longitudes at these indices\n",
    "                                lat_for_idw    = [ref_lat[i] for i in neigh10] #----------------------------Extract latitudes also\n",
    "                                coors_for_idw  = [(i,j) for i,j in zip(lat_for_idw,lon_for_idw)] \n",
    "                                \n",
    "                                nrb_01          = [nrb1[i] for i in neigh10]  #---------------------------Find variable values at nearest neighbors\n",
    "                                nrb_02          = [nrb2[i] for i in neigh10]\n",
    "                                func_nrb_01     = idw(coors_for_idw, nrb_01) #---------------------------Create inverse distance weighing (IDW) interpolation function at nn coordinates\n",
    "                                func_nrb_02     = idw(coors_for_idw, nrb_02)\n",
    "                                interp_nrb1     = func_nrb_01(target)        #-----------------------------------Find interpolated hourly par at target\n",
    "                                interp_nrb2     = func_nrb_02(target)\n",
    "\n",
    "                                Each_Ref_Tile_Data.append((sif_sid[sub], sif_lat[sub], sif_lon[sub], interp_nrb1, interp_nrb2))\n",
    "\n",
    "\n",
    "        DG = pd.DataFrame(np.array(Each_Ref_Tile_Data),columns=['sounding_id','latitude','longitude','nrb1','nrb2'])\n",
    "        DG.to_csv('Optimization/{}_ref_{}.csv'.format(sif_date,shape2[0]),index=False)\n",
    "        print('\\n')\n",
    "        b  = tttt.time()\n",
    "        printmd('**{} minutes**'.format((b-a)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3413, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sounding_id    2.018050e+15\n",
       "1_p_200        1.471861e+02\n",
       "1_p_400        1.415891e+02\n",
       "1_p_600        9.027400e+01\n",
       "1_p_800        9.623598e+01\n",
       "1_p_1200       1.424587e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day               = '03'\n",
    "df                = pd.read_csv('Optimization/2018-05-{}_ref_2400.csv'.format(day))\n",
    "df['sounding_id'] = df['sounding_id'].map(lambda x: int(x))\n",
    "\n",
    "list_of_refs = sorted(glob.glob('Optimization/2018-05-{}_*.csv'.format(day)))\n",
    "list_of_refs.remove('Optimization/2018-05-{}_ref_2400.csv'.format(day))\n",
    "\n",
    "for i in list_of_refs:\n",
    "    dg                = pd.read_csv(i)\n",
    "    dg['sounding_id'] = dg['sounding_id'].map(lambda x: int(x))   \n",
    "    dg['1_p']         = abs(dg['nrb1'] - df['nrb1']) * 100 / df['nrb1']\n",
    "    #dg['2_p']         = abs(dg['nrb2'] - df['nrb2']) * 100 / df['nrb2']\n",
    "    dg                = dg.rename({'1_p':'1_p_{}'.format(i[28:-4])},axis=1)#, '2_p':'2_p_{}'.format(i[28:-4])}, axis=1)\n",
    "    dg.to_csv('Optimization/2018-05-{}_REF_{}.csv'.format(day,i[28:-4]), index=False)\n",
    "    del dg\n",
    "\n",
    "da = pd.read_csv('Optimization/2018-05-{}_REF_200.csv'.format(day) )\n",
    "db = pd.read_csv('Optimization/2018-05-{}_REF_400.csv'.format(day) )\n",
    "dc = pd.read_csv('Optimization/2018-05-{}_REF_600.csv'.format(day) )\n",
    "dd = pd.read_csv('Optimization/2018-05-{}_REF_800.csv'.format(day) )\n",
    "de = pd.read_csv('Optimization/2018-05-{}_REF_1200.csv'.format(day))\n",
    "df = pd.read_csv('Optimization/2018-05-{}_ref_2400.csv'.format(day))\n",
    "\n",
    "dx1 = df. merge(da, on=['sounding_id','latitude','longitude'], how='inner')\n",
    "dx2 = dx1.merge(db, on=['sounding_id','latitude','longitude'], how='inner')\n",
    "dx3 = dx2.merge(dc, on=['sounding_id','latitude','longitude'], how='inner')\n",
    "dx4 = dx3.merge(dd, on=['sounding_id','latitude','longitude'], how='inner')\n",
    "dx5 = dx4.merge(de, on=['sounding_id','latitude','longitude'], how='inner')\n",
    "\n",
    "dx5['sounding_id'].nunique()\n",
    "#dx6 = dx5[['sounding_id','1_p_200','2_p_200','1_p_400','2_p_400','1_p_600','2_p_600','1_p_800','2_p_800','1_p_1200','2_p_1200',]]\n",
    "dx6 = dx5[['sounding_id','1_p_200','1_p_400','1_p_600','1_p_800','1_p_1200']]\n",
    "dx6 = dx6.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "dx6.shape\n",
    "dx7 = dx6.mean()\n",
    "dx7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx    = [200,400,600,800,1200]\n",
    "yy1_1 = [abs(i) for i in list(dx7[1:])]\n",
    "#yy1_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy2_1 = [abs(i) for i in list(dx7[1:])]\n",
    "#yy2_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy3_1 = [abs(i) for i in list(dx7[1:])]\n",
    "#yy3_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy4_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy4_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy5_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy5_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy6_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy6_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy7_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy7_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy8_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy8_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy9_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy9_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy10_1 = [abs(i) for i in list(dx7[1::2])]\n",
    "yy10_2 = [abs(i) for i in list(dx7[2::2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph Reflectance Band 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "dates = ['2018-05-01','2018-05-02','2018-05-03']#,'2018-05-04','2018-05-05','2018-05-06','2018-05-07','2018-05-08','2018-05-09','2018-05-10']\n",
    "rfls1 = [yy1_1, yy2_1, yy3_1]#, yy4_1, yy5_1, yy6_1, yy7_1, yy8_1, yy9_1, yy10_1]\n",
    "#rfls2 = [yy1_2, yy2_2, yy3_2]#, yy4_2, yy5_2, yy6_2, yy7_2, yy8_2, yy9_2, yy10_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([103.65855989471396,\n",
       "  108.87315685528334,\n",
       "  98.95099009045086,\n",
       "  100.06857794351984,\n",
       "  89.12454314520423],\n",
       " [77.63754088720547,\n",
       "  81.02570714604362,\n",
       "  72.32431530958031,\n",
       "  73.14937387963286,\n",
       "  74.18994579335524])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy1_1, yy2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1200]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103.65855989471396,\n",
       " 108.87315685528334,\n",
       " 98.95099009045086,\n",
       " 100.06857794351984,\n",
       " 89.12454314520423]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfls1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efbea987e48>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb86bb4898>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efbea976588>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efb8285f0f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Subsamples')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage Difference')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Reflectance_Band_1_10')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xx = [200,400,600]\n",
    "for i,j in zip(rfls1, dates):# , [yy1_2, yy2_2, yy3_2]):\n",
    "    plt.plot(xx,i, label=j)\n",
    "plt.legend()\n",
    "plt.xlabel('Subsamples')\n",
    "plt.ylabel('Percentage Difference')\n",
    "plt.title('Reflectance_Band_1_10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph Reflectance Band 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "for i,j in zip(rfls2, dates):\n",
    "    plt.plot(xx,i, label=j)\n",
    "plt.legend()\n",
    "plt.xlabel('Subsamples')\n",
    "plt.ylabel('Percentage Difference')\n",
    "plt.title('Reflectance_Band_2_10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Optimization/ && rm -r *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
