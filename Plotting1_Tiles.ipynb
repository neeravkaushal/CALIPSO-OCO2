{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell  #---- Output all jupyter lab inputs instead of the last one\n",
    "from IPython.display import Markdown, display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"             \n",
    "import glob #---------------------------------------------------- To read the files or folders in a system directory\n",
    "from netCDF4 import Dataset #------------------------------------ To read nc , nc4 and hdf4 files\n",
    "import numpy as np\n",
    "import datetime\n",
    "import h5py #---------------------------------------------------- To read hdf5 files\n",
    "from scipy import spatial #-------------------------------------- To extract the values and indices of k nearest neighbors\n",
    "import pandas as pd\n",
    "from ast import literal_eval #----------------------------------- For literal evaluation of a string to extract python objects\n",
    "from pyproj import Proj, transform #----------------------------- To interconvert different projections\n",
    "import warnings #------------------------------------------------ To suppress warnings\n",
    "from photutils.utils import ShepardIDWInterpolator as idw #------ To use Shepard's Inverse Distance Weighing Interpolation tool\n",
    "import re #------------------------------------------------------ To replace characters in a string\n",
    "import time as tttt\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter('ignore')\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_proj  = Proj('+proj=sinu +R=6371007.181 +nadgrids=@null +wktext') #------ Specify input projection\n",
    "out_proj = Proj(init='epsg:4326') #----------------------------------------- Specify output projection\n",
    "\n",
    "def Times(x): #------------------------------------------Extract Time from sounding ID. NOTE the time format is HH:MM:SSSS\n",
    "    y   = str(x)\n",
    "    yy  = y[8:]\n",
    "    yyy = '{}:{}:{}'.format(yy[:2], yy[2:4], yy[4:])\n",
    "    return yyy\n",
    "\n",
    "hours = [0, 3000000, 6000000, 9000000, 12000000, 15000000, 18000000, 21000000, 23595900]\n",
    "def f(x): #---------------------------------------------Extract the hour interval of sif time (which  is in seconds)\n",
    "    for i in range(len(hours)):\n",
    "        if (x>hours[i]) and (x<hours[i+1]):\n",
    "            lb = hours[i]\n",
    "            ub = hours[i+1]\n",
    "            return lb,ub\n",
    "            break\n",
    "\n",
    "def format_time(t): #----------------------------------- Format the time into HH:MM:SSSS for the raw format HH:MM:SSSSSSSS\n",
    "    s = t\n",
    "    return s[:-4]\n",
    "\n",
    "def nn(latitude_list,longitude_list,target): #---------- Find the index of nearest neighbor (NOTE: absolute difference)\n",
    "    target_lat, target_lon = target[1], target[0]\n",
    "    d = [abs(latitude-target_lat) + abs(longitude-target_lon) for latitude,longitude in zip(latitude_list,longitude_list)]\n",
    "    return np.argmin(d)\n",
    "\n",
    "data = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3)\n",
    "def tile_finder(Lat,Lon): #----------------------------- Find modis tile numbers in which the argument lat,lon lies\n",
    "    in_tile = False\n",
    "    i = 0\n",
    "    while(not in_tile):\n",
    "        in_tile = Lat >= data[i, 4] and Lat <= data[i, 5] and Lon >= data[i, 2] and Lon <= data[i, 3]\n",
    "        i += 1\n",
    "    V = str(int(data[i-1, 0])).zfill(2)\n",
    "    H = str(int(data[i-1, 1])).zfill(2)\n",
    "    return H,V\n",
    "\n",
    "def extract_pixel_coordinates(ULx,Uly,LRx,LRy,shape):\n",
    "    x        = np.linspace(ULx, LRx, shape[0], endpoint=False) + abs((ULx-LRx)/(2*shape[0]))\n",
    "    y        = np.linspace(ULy, LRy, shape[0], endpoint=False) - abs((ULy-LRy)/(2*shape[0]))\n",
    "    xx, yy   = np.meshgrid(x,y)\n",
    "    plon, plat = transform(in_proj, out_proj, xx, yy)\n",
    "    #mlon, mlat = plon[0], np.array([i[0] for i in plat])\n",
    "    plon       = plon.flatten()\n",
    "    plat       = plat.flatten()\n",
    "    return plon, plat#, mlon, mlat\n",
    "\n",
    "def temporal_interpolation(time1,val1,time2,val2,timeX):\n",
    "    df    = pd.DataFrame( [(time1, val1) , (time2, val2)] , columns=['Times','Values'] ) \n",
    "    df    = df.set_index('Times')\n",
    "    df    = pd.Series(df['Values'], index=df.index)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    inter = df.resample('S').interpolate(method='linear')\n",
    "    valX  = inter.loc[timeX]\n",
    "    return valX\n",
    "\n",
    "sif_file_list     = sorted(glob.glob('OCO2_sif/*.nc4'))    #--------------------------------------------- List of all OCO2 files\n",
    "calipso_file_list = sorted(glob.glob('OCO2_calipso/*.h5')) #--------------------------------------------- List of all OCO2-CALIPSO files\n",
    "fpar_file_list    = sorted(glob.glob('MCD15A3H/*.hdf'))    \n",
    "par_folder_list   = sorted(glob.glob('MCD18A2/*'))\n",
    "ref_folder_list   = sorted(glob.glob('MCD43A4/*'))\n",
    "data              = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3) #------ File having tile numbers and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**For 2018-05-01, there are 12081 sif footprints scattered over 46 tiles.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Processing shape :  2400 x 2400\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<cartopy.mpl.feature_artist.FeatureArtist at 0x7fed4c0a2128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF\n",
      "[-85.50118255615234, -85.5136947631836] [39.88534927368164, 39.925201416015625]\n",
      "REF\n",
      "[-104.42667749 -104.42123846 -104.41579943 ...  -80.842763    -80.83795164\n",
      "  -80.83314029] [39.99791666 39.99791666 39.99791666 ... 30.00208333 30.00208333\n",
      " 30.00208333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fed4c0a23c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fed4c0a28d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "for sif_file in sif_file_list: #---------------------------------------------------------------------------Read one sif file at a time\n",
    "    sif_date        = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%Y-%m-%d\") #-----Extract sif date\n",
    "    sif_julian_day  = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%j\") #-----------Extract sif julian day\n",
    "    sif             = Dataset(sif_file, mode='r') #-----------------------------------------------------------Open sif file\n",
    "    calipso_df_list = [] #------------------------------------------------------------------------------------Create an empty list\n",
    "    for calipso_file in calipso_file_list: #------------------------------------------------------------------Loop through all calipso files\n",
    "        calipso_date      = datetime.datetime.strptime(calipso_file.split('_')[5], '%y%m%d').strftime(\"%Y-%m-%d\")\n",
    "        if calipso_date  == sif_date: #----------------------------------------------------------------------------If calipso date matches sif date,\n",
    "            calipso       = h5py.File(calipso_file, mode='r') #----------------------------------------------------open the calipso file\n",
    "            calipso_ID    = calipso['OCO2_sounding_id'                                           ][:]\n",
    "            calipso_dist  = calipso['matchup_distance_km'                                        ][:]\n",
    "            calipso_index = calipso['matchup_Xindex'                                             ][:]\n",
    "            calipso_dfs   = pd.DataFrame({'sounding_id':calipso_ID.flatten(),'Xindex':calipso_index.flatten(),'Xdistance':calipso_dist.flatten()}) #-----Create dataframe with variables\n",
    "            calipso_dfs[calipso_dfs.Xindex==-999.0] = np.nan #------- Replace missing values with nan\n",
    "            calipso_dfs.dropna(inplace=True) #----------------------- Drop missing values of Xindex\n",
    "            calipso_dfs[calipso_dfs.Xdistance>=2.0] = np.nan\n",
    "            calipso_dfs.dropna(inplace=True)\n",
    "            calipso_df_list.append(calipso_dfs) #-------------------- Add all calipso dataframes into a list\n",
    "    calipso_df                     = pd.concat(calipso_df_list, ignore_index = True).drop_duplicates() #---------Create a final calipso dataframe for a day\n",
    "\n",
    "    cloud_albedo                   = sif.groups['Cloud'].variables['albedo'                 ][:].flatten() #--------Read sif variables and flatten them\n",
    "    cloud_flag                     = sif.groups['Cloud'].variables['cloud_flag'             ][:].flatten()\n",
    "    cloud_co2_ratio                = sif.groups['Cloud'].variables['co2_ratio'              ][:].flatten()\n",
    "    cloud_delta_surface_pressure   = sif.groups['Cloud'].variables['delta_surface_pressure' ][:].flatten()\n",
    "    cloud_o2_ratio                 = sif.groups['Cloud'].variables['o2_ratio'               ][:].flatten()\n",
    "    vapor_pressure_deficit         = sif.groups['Meteo'].variables['vapor_pressure_deficit' ][:].flatten()\n",
    "    temperature_2m                 = sif.groups['Meteo'].variables['2m_temperature'         ][:].flatten()\n",
    "    temperature_skin               = sif.groups['Meteo'].variables['skin_temperature'       ][:].flatten()\n",
    "    specific_humidity              = sif.groups['Meteo'].variables['specific_humidity'      ][:].flatten()\n",
    "    surface_pressure               = sif.groups['Meteo'].variables['surface_pressure'       ][:].flatten()\n",
    "    wind_speed                     = sif.groups['Meteo'].variables['wind_speed'             ][:].flatten()\n",
    "    continuum_radiance_757nm       = sif.variables         ['continuum_radiance_757nm'      ][:].flatten()\n",
    "    continuum_radiance_771nm       = sif.variables         ['continuum_radiance_771nm'      ][:].flatten()\n",
    "    daily_correction_factor        = sif.variables         ['daily_correction_factor'       ][:].flatten()\n",
    "    footprint                      = sif.variables         ['footprint'                     ][:].flatten()\n",
    "    IGBP_index                     = sif.variables         ['IGBP_index'                    ][:].flatten()\n",
    "    latitude                       = sif.variables         ['latitude'                      ][:].flatten()\n",
    "    longitude                      = sif.variables         ['longitude'                     ][:].flatten()\n",
    "    measurement_mode               = sif.variables         ['measurement_mode'              ][:].flatten()\n",
    "    orbit_number                   = sif.variables         ['orbit_number'                  ][:].flatten()\n",
    "    reduced_chi2_757nm             = sif.variables         ['reduced_chi2_757nm'            ][:].flatten()\n",
    "    reduced_chi2_771nm             = sif.variables         ['reduced_chi2_771nm'            ][:].flatten()\n",
    "    sensor_azimuth_angle           = sif.variables         ['sensor_azimuth_angle'          ][:].flatten()\n",
    "    sensor_zenith_angle            = sif.variables         ['sensor_zenith_angle'           ][:].flatten()\n",
    "    SIF_757nm                      = sif.variables         ['SIF_757nm'                     ][:].flatten() #----------Use this condition for next block\n",
    "    SIF_757nm_relative             = sif.variables         ['SIF_757nm_relative'            ][:].flatten()\n",
    "    SIF_757nm_uncert               = sif.variables         ['SIF_757nm_uncert'              ][:].flatten()\n",
    "    SIF_771nm                      = sif.variables         ['SIF_771nm'                     ][:].flatten()\n",
    "    SIF_771nm_relative             = sif.variables         ['SIF_771nm_relative'            ][:].flatten()\n",
    "    SIF_771nm_uncert               = sif.variables         ['SIF_771nm_uncert'              ][:].flatten()\n",
    "    solar_azimuth_angle            = sif.variables         ['solar_azimuth_angle'           ][:].flatten()\n",
    "    solar_zenith_angle             = sif.variables         ['solar_zenith_angle'            ][:].flatten()\n",
    "    sounding_id                    = sif.variables         ['sounding_id'                   ][:].flatten()\n",
    "    surface_altitude               = sif.variables         ['surface_altitude'              ][:].flatten()\n",
    "    time                           = sif.variables         ['time'                          ][:].flatten()\n",
    "    uncorrected_SIF_757nm          = sif.variables         ['uncorrected_SIF_757nm'         ][:].flatten()\n",
    "    uncorrected_SIF_757nm_relative = sif.variables         ['uncorrected_SIF_757nm_relative'][:].flatten()\n",
    "    uncorrected_SIF_771nm          = sif.variables         ['uncorrected_SIF_771nm'         ][:].flatten()\n",
    "    uncorrected_SIF_771nm_relative = sif.variables         ['uncorrected_SIF_771nm_relative'][:].flatten()\n",
    "      \n",
    "    sif_rows  = [(SIF_757nm[i], cloud_albedo[i], cloud_flag[i], cloud_co2_ratio[i], cloud_delta_surface_pressure[i], cloud_o2_ratio[i], vapor_pressure_deficit[i],\n",
    "                  temperature_2m[i], temperature_skin[i], specific_humidity[i], surface_pressure[i], wind_speed[i], continuum_radiance_757nm[i],\n",
    "                  continuum_radiance_771nm[i],daily_correction_factor[i], footprint[i], IGBP_index[i], latitude[i], longitude[i], measurement_mode[i],\n",
    "                  orbit_number[i], reduced_chi2_757nm[i],reduced_chi2_771nm[i], sensor_azimuth_angle[i], sensor_zenith_angle[i], SIF_757nm_relative[i],\n",
    "                  SIF_757nm_uncert[i], SIF_771nm[i],SIF_771nm_relative[i], SIF_771nm_uncert[i], solar_azimuth_angle[i], solar_zenith_angle[i], sounding_id[i],\n",
    "                  surface_altitude[i], time[i], uncorrected_SIF_757nm[i], uncorrected_SIF_757nm_relative[i], uncorrected_SIF_771nm[i], uncorrected_SIF_771nm_relative[i])\n",
    "                  for i in range(0,len(sounding_id))]\n",
    "    \n",
    "    column_labels = ['SIF_757nm', 'cloud_albedo', 'cloud_flag', 'cloud_co2_ratio', 'cloud_delta_surface_pressure', 'cloud_o2_ratio', 'vapor_pressure_deficit',\n",
    "                     'temperature_2m', 'temperature_skin', 'specific_humidity', 'surface_pressure', 'wind_speed', 'continuum_radiance_757nm',\n",
    "                     'continuum_radiance_771nm','daily_correction_factor', 'footprint', 'IGBP_index', 'latitude', 'longitude', 'measurement_mode',\n",
    "                     'orbit_number', 'reduced_chi2_757nm','reduced_chi2_771nm', 'sensor_azimuth_angle', 'sensor_zenith_angle',\n",
    "                     'SIF_757nm_relative', 'SIF_757nm_uncert', 'SIF_771nm','SIF_771nm_relative', 'SIF_771nm_uncert', 'solar_azimuth_angle', 'solar_zenith_angle',\n",
    "                     'sounding_id', 'surface_altitude', 'time','uncorrected_SIF_757nm', 'uncorrected_SIF_757nm_relative', 'uncorrected_SIF_771nm',\n",
    "                     'uncorrected_SIF_771nm_relative']\n",
    "     \n",
    "    sif_df                         = pd.DataFrame(sif_rows,columns = column_labels) #-------- Create sif variables' dataframe\n",
    "    calipso_sif_merger             = pd.merge(sif_df, calipso_df, on = ['sounding_id'], how = 'inner') #--------Merge sif and calipso on sounding _id\n",
    "    calipso_sif_merger['Date']     = calipso_sif_merger['sounding_id'].map(lambda x: '-'.join([str(x)[:4],str(x)[4:6],str(x)[6:]])[:10]) #-----Create new date column\n",
    "    calipso_sif_merger['SIF_Time'] = calipso_sif_merger['sounding_id'].map(lambda x: Times(x))  #----------------------------------------------Create new time column\n",
    "    calipso_sif_merger['tile_h'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[0], axis=1) #------Create new horizontal tile column\n",
    "    calipso_sif_merger['tile_v'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[1], axis=1) #------Create new vertical tile column\n",
    "    calipso_sif_merger             = calipso_sif_merger.dropna(how='any')\n",
    "\n",
    "    grp         = calipso_sif_merger.groupby(['tile_h', 'tile_v']).agg(lambda x: list(x))  #----Group sif-calipso merger(from now on called SIF*) by tile id\n",
    "    grp         = grp.reset_index() #-----------------------------------------------------------Reset indices\n",
    "    l_ungrouped = len(calipso_sif_merger)\n",
    "    l_grouped   = len(grp)\n",
    "    df          = grp.copy() #--------make a copy of the grouped file\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    printmd('**For {}, there are {} sif footprints scattered over {} tiles.**'.format(sif_date, l_ungrouped, l_grouped))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------')  \n",
    "\n",
    "    shapes              = [(2400,2400)]\n",
    "    for shape2 in shapes:\n",
    "        print('Processing shape : ', shape2[0],'x',shape2[1])\n",
    "        a                   = tttt.time()\n",
    "        print('REF Processing Started...\\n')\n",
    "        Each_Ref_Tile_Data  = []\n",
    "        for index,h_sif,v_sif,sif_lon,sif_lat,sif_time,sif_sid in zip(df.index,df['tile_h'],df['tile_v'],df['longitude'],df['latitude'],df['SIF_Time'],df['sounding_id']):\n",
    "            print('h{}v{}'.format(h_sif,v_sif), flush = True, sep=',', end=' ')\n",
    "\n",
    "            for folder_number in range(len(ref_folder_list)):\n",
    "                ref_julian_day    = ref_folder_list[folder_number].split('/')[1]\n",
    "\n",
    "                if sif_julian_day == ref_julian_day:\n",
    "                    ref_file_list = glob.glob(ref_folder_list[folder_number]+'/*.hdf')\n",
    "\n",
    "                    for num3,ref_file in enumerate(ref_file_list):\n",
    "                        h_ref = ref_file.split('.')[2][1:3]\n",
    "                        v_ref = ref_file.split('.')[2][4:6]\n",
    "\n",
    "                        if (h_ref==h_sif) and (v_ref==v_sif):\n",
    "                            ref              = Dataset(ref_file, mode='r')\n",
    "                            struct           = getattr(ref, 'StructMetadata.0')\n",
    "                            struct1          = struct[struct.find('UpperLeftPointMtrs'): struct.find('LowerRightMtrs')][19:-3]\n",
    "                            struct2          = struct[struct.find('LowerRightMtrs')    : struct.find('Projection')    ][15:-3]\n",
    "                            ULx, ULy         = literal_eval(struct1)\n",
    "                            LRx, LRy         = literal_eval(struct2)\n",
    "                            ref_lon,ref_lat  = extract_pixel_coordinates(ULx,ULy,LRx,LRy,shape2)\n",
    "                            if (h_ref,v_ref) in [('10','05') , ('10','08'), ('10','10'), ('11','03'), ('12','03'), ('12','12'), ('19','04')]:\n",
    "                                                       \n",
    "\n",
    "                                plt.figure()\n",
    "                                ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "                                ax.coastlines()\n",
    "                                print('SIF')\n",
    "                                print(sif_lon,sif_lat)\n",
    "                                print('REF')\n",
    "                                print(ref_lon, ref_lat)\n",
    "                                plt.scatter(ref_lon, ref_lat, s=0.1 , c='b');\n",
    "                                plt.scatter(sif_lon, sif_lat, s=1, c='r');\n",
    "                                plt.savefig('Images/XXXh{}v{}'.format(h_sif,v_sif),dpi=500);\n",
    "                                break\n",
    "                            \n",
    "                        \n",
    "                    break\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
