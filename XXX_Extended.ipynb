{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell  #---- Output all jupyter lab inputs instead of the last one\n",
    "from IPython.display import Markdown, display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"             \n",
    "import glob #---------------------------------------------------- To read the files or folders in a system directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pyresample\n",
    "import ESMF\n",
    "import h5py #---------------------------------------------------- To read hdf5 files\n",
    "import re #------------------------------------------------------ To replace characters in a string\n",
    "import time as tttt\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Proj, transform \n",
    "from cartopy import crs, feature\n",
    "from photutils.utils import ShepardIDWInterpolator as idw #------ To use Shepard's Inverse Distance Weighing Interpolation tool\n",
    "from netCDF4 import Dataset #------------------------------------ To read nc , nc4 and hdf4 files\n",
    "from scipy import spatial #-------------------------------------- To extract the values and indices of k nearest neighbors\n",
    "from ast import literal_eval #----------------------------------- For literal evaluation of a string to extract python objects\n",
    "from pyproj import Proj, transform #----------------------------- To interconvert different projections\n",
    "from matplotlib import cm, gridspec, rcParams\n",
    "FORTRAN_CONTIGUOUS = True\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Times(x): #------------------------------------------Extract Time from sounding ID. NOTE the time format is HH:MM:SSSS\n",
    "    y   = str(x)\n",
    "    yy  = y[8:]\n",
    "    yyy = '{}:{}:{}'.format(yy[:2], yy[2:4], yy[4:])\n",
    "    return yyy\n",
    "\n",
    "hours = [0, 3000000, 6000000, 9000000, 12000000, 15000000, 18000000, 21000000, 23595900]\n",
    "def f(x): #---------------------------------------------Extract the hour interval of sif time (which  is in seconds)\n",
    "    for i in range(len(hours)):\n",
    "        if (x>hours[i]) and (x<hours[i+1]):\n",
    "            lb = hours[i]\n",
    "            ub = hours[i+1]\n",
    "            return lb,ub\n",
    "            break\n",
    "            \n",
    "def format_time(t): #----------------------------------- Format the time into HH:MM:SSSS for the raw format HH:MM:SSSSSSSS\n",
    "    s = t\n",
    "    return s[:-4]\n",
    "\n",
    "def nn(latitude_list,longitude_list,target): #---------- Find the index of nearest neighbor (NOTE: absolute difference)\n",
    "    target_lat, target_lon = target[1], target[0]\n",
    "    d = [abs(latitude-target_lat) + abs(longitude-target_lon) for latitude,longitude in zip(latitude_list,longitude_list)]\n",
    "    return np.argmin(d)\n",
    "\n",
    "data = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3)\n",
    "def tile_finder(Lat,Lon): #----------------------------- Find modis tile numbers in which the argument lat,lon lies\n",
    "    in_tile = False\n",
    "    i = 0\n",
    "    while(not in_tile):\n",
    "        in_tile = Lat >= data[i, 4] and Lat <= data[i, 5] and Lon >= data[i, 2] and Lon <= data[i, 3]\n",
    "        i += 1\n",
    "    V = str(int(data[i-1, 0])).zfill(2)\n",
    "    H = str(int(data[i-1, 1])).zfill(2)\n",
    "    return H,V\n",
    "\n",
    "def temporal_interpolation(time1,val1,time2,val2,timeX):\n",
    "    df    = pd.DataFrame( [(time1, val1) , (time2, val2)] , columns=['Times','Values'] ) \n",
    "    df    = df.set_index('Times')\n",
    "    df    = pd.Series(df['Values'], index=df.index)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    inter = df.resample('S').interpolate(method='linear')\n",
    "    valX  = inter.loc[timeX]\n",
    "    return valX\n",
    "\n",
    "def extract_pixel_coordinates(ULx,Uly,LRx,LRy,shape):\n",
    "    in_proj  = Proj('+proj=sinu +R=6371007.181 +nadgrids=@null +wktext') #------ Specify input projection\n",
    "    out_proj = Proj(init='epsg:4326')\n",
    "    x        = np.linspace(ULx, LRx, shape[0], endpoint=False) + abs((ULx-LRx)/(2*shape[0]))\n",
    "    y        = np.linspace(ULy, LRy, shape[0], endpoint=False) - abs((ULy-LRy)/(2*shape[0]))\n",
    "    xx, yy   = np.meshgrid(x,y)\n",
    "    plon, plat = transform(in_proj, out_proj, xx, yy)\n",
    "    mlon, mlat = plon[0], np.array([i[0] for i in plat])\n",
    "    plon       = plon.flatten()\n",
    "    plat       = plat.flatten()\n",
    "    return plon, plat, mlon, mlat\n",
    "\n",
    "sif_file_list     = sorted(glob.glob('OCO2_sif/*.nc4'))    #--------------------------------------------- List of all OCO2 files\n",
    "calipso_file_list = sorted(glob.glob('OCO2_calipso/*.h5')) #--------------------------------------------- List of all OCO2-CALIPSO files\n",
    "fpar_file_list    = sorted(glob.glob('MCD15A3H/*.hdf'))    \n",
    "par_folder_list   = sorted(glob.glob('MCD18A2/*'))\n",
    "ref_folder_list   = sorted(glob.glob('MCD43A4/*'))\n",
    "data              = np.genfromtxt('sn_bound_10deg.txt', skip_header = 7, skip_footer = 3) #------ File having tile numbers and IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read reflectance file and extract variables and coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**For 2018-05-01, there are 12081 sif footprints scattered over 46 tiles.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "REF Processing Started...\n",
      "\n",
      "h10v05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaushal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:137: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h10v06 h10v08 h10v09 h10v10 h11v03 h11v04 h11v11 h12v02 h12v03 h12v12 h12v13 h13v01 h13v02 h13v13 h14v01 h17v00 h18v00 h18v01 h18v03 h18v04 h19v01 h19v02 h19v06 h19v07 h20v03 h20v08 h20v09 h20v10 h20v11 h20v12 h21v02 h21v04 h22v04 h23v03 h23v06 h24v04 h25v04 h27v12 h28v06 h28v11 h29v07 h29v08 h29v10 h29v11 h30v09 "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shape2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2c443828b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mDG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEach_Ref_Tile_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sounding_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nrb1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nrb2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mDG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimization/{}_ref_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msif_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mb\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtttt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape2' is not defined"
     ]
    }
   ],
   "source": [
    "for sif_file in sif_file_list: #---------------------------------------------------------------------------Read one sif file at a time\n",
    "    sif_date        = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%Y-%m-%d\") #-----Extract sif date\n",
    "    sif_julian_day  = datetime.datetime.strptime(sif_file.split('_')[3], '%y%m%d').strftime(\"%j\") #-----------Extract sif julian day\n",
    "    sif             = Dataset(sif_file, mode='r') #-----------------------------------------------------------Open sif file\n",
    "    calipso_df_list = [] #------------------------------------------------------------------------------------Create an empty list\n",
    "    for calipso_file in calipso_file_list: #------------------------------------------------------------------Loop through all calipso files\n",
    "        calipso_date      = datetime.datetime.strptime(calipso_file.split('_')[5], '%y%m%d').strftime(\"%Y-%m-%d\")\n",
    "        if calipso_date  == sif_date: #----------------------------------------------------------------------------If calipso date matches sif date,\n",
    "            calipso       = h5py.File(calipso_file, mode='r') #----------------------------------------------------open the calipso file\n",
    "            calipso_ID    = calipso['OCO2_sounding_id'                                           ][:]\n",
    "            calipso_dist  = calipso['matchup_distance_km'                                        ][:]\n",
    "            calipso_index = calipso['matchup_Xindex'                                             ][:]\n",
    "            calipso_dfs   = pd.DataFrame({'sounding_id':calipso_ID.flatten(),'Xindex':calipso_index.flatten(),'Xdistance':calipso_dist.flatten()}) #-----Create dataframe with variables\n",
    "            calipso_dfs[calipso_dfs.Xindex==-999.0] = np.nan #------- Replace missing values with nan\n",
    "            calipso_dfs.dropna(inplace=True) #----------------------- Drop missing values of Xindex\n",
    "            calipso_dfs[calipso_dfs.Xdistance>=2.0] = np.nan\n",
    "            calipso_dfs.dropna(inplace=True)\n",
    "            calipso_df_list.append(calipso_dfs) #-------------------- Add all calipso dataframes into a list\n",
    "    calipso_df                     = pd.concat(calipso_df_list, ignore_index = True).drop_duplicates() #---------Create a final calipso dataframe for a day\n",
    "\n",
    "    cloud_albedo                   = sif.groups['Cloud'].variables['albedo'                 ][:].flatten() #--------Read sif variables and flatten them\n",
    "    cloud_flag                     = sif.groups['Cloud'].variables['cloud_flag'             ][:].flatten()\n",
    "    cloud_co2_ratio                = sif.groups['Cloud'].variables['co2_ratio'              ][:].flatten()\n",
    "    cloud_delta_surface_pressure   = sif.groups['Cloud'].variables['delta_surface_pressure' ][:].flatten()\n",
    "    cloud_o2_ratio                 = sif.groups['Cloud'].variables['o2_ratio'               ][:].flatten()\n",
    "    vapor_pressure_deficit         = sif.groups['Meteo'].variables['vapor_pressure_deficit' ][:].flatten()\n",
    "    temperature_2m                 = sif.groups['Meteo'].variables['2m_temperature'         ][:].flatten()\n",
    "    temperature_skin               = sif.groups['Meteo'].variables['skin_temperature'       ][:].flatten()\n",
    "    specific_humidity              = sif.groups['Meteo'].variables['specific_humidity'      ][:].flatten()\n",
    "    surface_pressure               = sif.groups['Meteo'].variables['surface_pressure'       ][:].flatten()\n",
    "    wind_speed                     = sif.groups['Meteo'].variables['wind_speed'             ][:].flatten()\n",
    "    continuum_radiance_757nm       = sif.variables         ['continuum_radiance_757nm'      ][:].flatten()\n",
    "    continuum_radiance_771nm       = sif.variables         ['continuum_radiance_771nm'      ][:].flatten()\n",
    "    daily_correction_factor        = sif.variables         ['daily_correction_factor'       ][:].flatten()\n",
    "    footprint                      = sif.variables         ['footprint'                     ][:].flatten()\n",
    "    IGBP_index                     = sif.variables         ['IGBP_index'                    ][:].flatten()\n",
    "    latitude                       = sif.variables         ['latitude'                      ][:].flatten()\n",
    "    longitude                      = sif.variables         ['longitude'                     ][:].flatten()\n",
    "    measurement_mode               = sif.variables         ['measurement_mode'              ][:].flatten()\n",
    "    orbit_number                   = sif.variables         ['orbit_number'                  ][:].flatten()\n",
    "    reduced_chi2_757nm             = sif.variables         ['reduced_chi2_757nm'            ][:].flatten()\n",
    "    reduced_chi2_771nm             = sif.variables         ['reduced_chi2_771nm'            ][:].flatten()\n",
    "    sensor_azimuth_angle           = sif.variables         ['sensor_azimuth_angle'          ][:].flatten()\n",
    "    sensor_zenith_angle            = sif.variables         ['sensor_zenith_angle'           ][:].flatten()\n",
    "    SIF_757nm                      = sif.variables         ['SIF_757nm'                     ][:].flatten() #----------Use this condition for next block\n",
    "    SIF_757nm_relative             = sif.variables         ['SIF_757nm_relative'            ][:].flatten()\n",
    "    SIF_757nm_uncert               = sif.variables         ['SIF_757nm_uncert'              ][:].flatten()\n",
    "    SIF_771nm                      = sif.variables         ['SIF_771nm'                     ][:].flatten()\n",
    "    SIF_771nm_relative             = sif.variables         ['SIF_771nm_relative'            ][:].flatten()\n",
    "    SIF_771nm_uncert               = sif.variables         ['SIF_771nm_uncert'              ][:].flatten()\n",
    "    solar_azimuth_angle            = sif.variables         ['solar_azimuth_angle'           ][:].flatten()\n",
    "    solar_zenith_angle             = sif.variables         ['solar_zenith_angle'            ][:].flatten()\n",
    "    sounding_id                    = sif.variables         ['sounding_id'                   ][:].flatten()\n",
    "    surface_altitude               = sif.variables         ['surface_altitude'              ][:].flatten()\n",
    "    time                           = sif.variables         ['time'                          ][:].flatten()\n",
    "    uncorrected_SIF_757nm          = sif.variables         ['uncorrected_SIF_757nm'         ][:].flatten()\n",
    "    uncorrected_SIF_757nm_relative = sif.variables         ['uncorrected_SIF_757nm_relative'][:].flatten()\n",
    "    uncorrected_SIF_771nm          = sif.variables         ['uncorrected_SIF_771nm'         ][:].flatten()\n",
    "    uncorrected_SIF_771nm_relative = sif.variables         ['uncorrected_SIF_771nm_relative'][:].flatten()\n",
    "      \n",
    "    sif_rows  = [(SIF_757nm[i], cloud_albedo[i], cloud_flag[i], cloud_co2_ratio[i], cloud_delta_surface_pressure[i], cloud_o2_ratio[i], vapor_pressure_deficit[i],\n",
    "                  temperature_2m[i], temperature_skin[i], specific_humidity[i], surface_pressure[i], wind_speed[i], continuum_radiance_757nm[i],\n",
    "                  continuum_radiance_771nm[i],daily_correction_factor[i], footprint[i], IGBP_index[i], latitude[i], longitude[i], measurement_mode[i],\n",
    "                  orbit_number[i], reduced_chi2_757nm[i],reduced_chi2_771nm[i], sensor_azimuth_angle[i], sensor_zenith_angle[i], SIF_757nm_relative[i],\n",
    "                  SIF_757nm_uncert[i], SIF_771nm[i],SIF_771nm_relative[i], SIF_771nm_uncert[i], solar_azimuth_angle[i], solar_zenith_angle[i], sounding_id[i],\n",
    "                  surface_altitude[i], time[i], uncorrected_SIF_757nm[i], uncorrected_SIF_757nm_relative[i], uncorrected_SIF_771nm[i], uncorrected_SIF_771nm_relative[i])\n",
    "                  for i in range(0,len(sounding_id))]\n",
    "    \n",
    "    column_labels = ['SIF_757nm', 'cloud_albedo', 'cloud_flag', 'cloud_co2_ratio', 'cloud_delta_surface_pressure', 'cloud_o2_ratio', 'vapor_pressure_deficit',\n",
    "                     'temperature_2m', 'temperature_skin', 'specific_humidity', 'surface_pressure', 'wind_speed', 'continuum_radiance_757nm',\n",
    "                     'continuum_radiance_771nm','daily_correction_factor', 'footprint', 'IGBP_index', 'latitude', 'longitude', 'measurement_mode',\n",
    "                     'orbit_number', 'reduced_chi2_757nm','reduced_chi2_771nm', 'sensor_azimuth_angle', 'sensor_zenith_angle',\n",
    "                     'SIF_757nm_relative', 'SIF_757nm_uncert', 'SIF_771nm','SIF_771nm_relative', 'SIF_771nm_uncert', 'solar_azimuth_angle', 'solar_zenith_angle',\n",
    "                     'sounding_id', 'surface_altitude', 'time','uncorrected_SIF_757nm', 'uncorrected_SIF_757nm_relative', 'uncorrected_SIF_771nm',\n",
    "                     'uncorrected_SIF_771nm_relative']\n",
    "     \n",
    "    sif_df                         = pd.DataFrame(sif_rows,columns = column_labels) #-------- Create sif variables' dataframe\n",
    "    calipso_sif_merger             = pd.merge(sif_df, calipso_df, on = ['sounding_id'], how = 'inner') #--------Merge sif and calipso on sounding _id\n",
    "    calipso_sif_merger['Date']     = calipso_sif_merger['sounding_id'].map(lambda x: '-'.join([str(x)[:4],str(x)[4:6],str(x)[6:]])[:10]) #-----Create new date column\n",
    "    calipso_sif_merger['SIF_Time'] = calipso_sif_merger['sounding_id'].map(lambda x: Times(x))  #----------------------------------------------Create new time column\n",
    "    calipso_sif_merger['tile_h'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[0], axis=1) #------Create new horizontal tile column\n",
    "    calipso_sif_merger['tile_v'  ] = calipso_sif_merger.apply(lambda x: tile_finder(x['latitude'], x['longitude'])[1], axis=1) #------Create new vertical tile column\n",
    "    calipso_sif_merger             = calipso_sif_merger.dropna(how='any')\n",
    "    grp                            = calipso_sif_merger.groupby(['tile_h', 'tile_v']).agg(lambda x: list(x))  #----Group sif-calipso merger(from now on called SIF*) by tile id\n",
    "    grp                            = grp.reset_index() #-----------------------------------------------------------Reset indices\n",
    "    l_ungrouped                    = len(calipso_sif_merger)\n",
    "    l_grouped                      = len(grp)\n",
    "    df                             = grp.copy() #--------make a copy of the grouped file\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    printmd('**For {}, there are {} sif footprints scattered over {} tiles.**'.format(sif_date, l_ungrouped, l_grouped))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------------------------------') \n",
    "    \n",
    "    #shapes              = [(2400,2400), (1200,1200), (800,800), (600,600), (400,400), (200,200)]\n",
    "    shapes              = [1200,800,600,400,200]\n",
    "    for shape in shapes:\n",
    "        #print('Processing shape : ', shape[0],'x',shape[1])\n",
    "        a                   = tttt.time()\n",
    "        print('REF Processing Started...\\n')\n",
    "        Each_Ref_Tile_Data  = []\n",
    "        for index,h_sif,v_sif,sif_lon,sif_lat,sif_time,sif_sid in zip(df.index,df['tile_h'],df['tile_v'],df['longitude'],df['latitude'],df['SIF_Time'],df['sounding_id']):\n",
    "            print('h{}v{}'.format(h_sif,v_sif), flush = True, sep=',', end=' ')\n",
    "\n",
    "            for folder_number in range(len(ref_folder_list)):\n",
    "                ref_julian_day    = ref_folder_list[folder_number].split('/')[1]\n",
    "\n",
    "                if sif_julian_day == ref_julian_day:\n",
    "                    ref_file_list = glob.glob(ref_folder_list[folder_number]+'/*.hdf')\n",
    "\n",
    "                    for num3,ref_file in enumerate(ref_file_list):\n",
    "                        h_ref = ref_file.split('.')[2][1:3]\n",
    "                        v_ref = ref_file.split('.')[2][4:6]\n",
    "\n",
    "                        if (h_ref==h_sif) and (v_ref==v_sif):\n",
    "                            ref      = Dataset('MCD43A4/121/MCD43A4.A2018121.h10v05.006.2018130033209.hdf', mode='r')\n",
    "                            struct   = getattr(ref, 'StructMetadata.0')\n",
    "                            struct1  = struct[struct.find('UpperLeftPointMtrs'): struct.find('LowerRightMtrs')][19:-3]\n",
    "                            struct2  = struct[struct.find('LowerRightMtrs')    : struct.find('Projection')    ][15:-3]\n",
    "                            ULx, ULy = literal_eval(struct1)\n",
    "                            LRx, LRy = literal_eval(struct2)\n",
    "                            ref_lon, ref_lat, ref_mlon, ref_mlat  = extract_pixel_coordinates(ULx,ULy,LRx,LRy,(2400,2400))\n",
    "                            lon_curv, lat_curv                    = np.meshgrid(ref_mlon, ref_mlat)\n",
    "\n",
    "                            nrb1a    = ref.variables['Nadir_Reflectance_Band1'][:]\n",
    "                            fv_ref1  = ref.variables['Nadir_Reflectance_Band1']._FillValue\n",
    "\n",
    "                            nrb2a    = ref.variables['Nadir_Reflectance_Band2'][:]\n",
    "                            fv_ref2  = ref.variables['Nadir_Reflectance_Band2']._FillValue\n",
    "                            \n",
    "                            lat1     = np.linspace(ref_mlat[0], ref_mlat[-1], shape, endpoint=True)# + abs((ref_mlat[0]-ref_mlat[-1])/(2*200))\n",
    "                            lon1     = np.linspace(ref_mlon[0], ref_mlon[-1], shape, endpoint=True)# - abs((ref_mlon[0]-ref_mlon[-1])/(2*200))\n",
    "\n",
    "                            lon_tar, lat_tar = np.meshgrid(lon1, lat1)\n",
    "                            \n",
    "                            # Resample original reflectance data (2400x2400) to desired shape (i.e. 1200x1200, 800x800, etc.) using PyResample\n",
    "                            targ_def = pyresample.geometry.SwathDefinition(lons=lon_tar   , lats=lat_tar)\n",
    "                            orig_def = pyresample.geometry.SwathDefinition(lons=lon_curv, lats=lat_curv)\n",
    "                            wf       = lambda r: 1/r**2\n",
    "                            nrb1_resampled = pyresample.kd_tree.resample_custom(orig_def, nrb1a, targ_def, radius_of_influence=500000, neighbours=4, weight_funcs=wf, fill_value=float(fv_ref1))\n",
    "                            nrb2_resampled = pyresample.kd_tree.resample_custom(orig_def, nrb2a, targ_def, radius_of_influence=500000, neighbours=4, weight_funcs=wf, fill_value=float(fv_ref2))\n",
    "\n",
    "                            #Take output (resampled data) from PyResample and use it as source data for ESMF Regridding. The output will be obtained at SIF Locations\n",
    "                            sourcegrid = ESMF.Grid(np.array((shape,shape)), staggerloc=ESMF.StaggerLoc.CENTER, coord_sys=ESMF.CoordSys.SPH_DEG);\n",
    "                            source_lon = sourcegrid.get_coords(0);\n",
    "                            source_lat = sourcegrid.get_coords(1);\n",
    "\n",
    "                            if FORTRAN_CONTIGUOUS:\n",
    "                                source_lon[...] = lon_tar.T\n",
    "                                source_lat[...] = lat_tar.T\n",
    "                            else:\n",
    "                                source_lon[...] = lon_tar\n",
    "                                source_lat[...] = lat_tar\n",
    "\n",
    "                            sourcefield1 = ESMF.Field(sourcegrid, name='Reflectance_Resampled1');\n",
    "                            sourcefield2 = ESMF.Field(sourcegrid, name='Reflectance_Resampled2');\n",
    "                            \n",
    "                            if FORTRAN_CONTIGUOUS:\n",
    "                                sourcefield1.data[...] = nrb1_resampled.T\n",
    "                                sourcefield2.data[...] = nrb2_resampled.T\n",
    "                            else:\n",
    "                                sourcefield1.data[...] = nrb1_resampled\n",
    "                                sourcefield2.data[...] = nrb2_resampled\n",
    "\n",
    "                            sif_lat  = np.array(sif_lat)\n",
    "                            sif_lon  = np.array(sif_lon)\n",
    "                            sif_loc  = ESMF.LocStream(len(sif_lat), coord_sys = ESMF.CoordSys.SPH_DEG, name = 'sif_locs');\n",
    "                            sif_loc['ESMF:Lat'] = sif_lat\n",
    "                            sif_loc['ESMF:Lon'] = sif_lon\n",
    "                            \n",
    "                            sif_data1 = ESMF.Field(sif_loc, name = 'Reflectance1_Interpolated_at_Sif_Locations')\n",
    "                            sif_data2 = ESMF.Field(sif_loc, name = 'Reflectance2_Interpolated_at_Sif_Locations')\n",
    "                            \n",
    "                            regrid1   = ESMF.Regrid(sourcefield1, sif_data1, regrid_method = ESMF.RegridMethod.NEAREST_STOD, unmapped_action = ESMF.UnmappedAction.IGNORE)\n",
    "                            regrid2   = ESMF.Regrid(sourcefield2, sif_data2, regrid_method = ESMF.RegridMethod.NEAREST_STOD, unmapped_action = ESMF.UnmappedAction.IGNORE)\n",
    "                            \n",
    "                            sif_data1 = regrid1(sourcefield1, sif_data1)\n",
    "                            sif_data2 = regrid2(sourcefield2, sif_data2)\n",
    "                            \n",
    "                            \n",
    "                            for sub in range(len(sif_data1.data)):\n",
    "                                Each_Ref_Tile_Data.append((sif_sid[sub], sif_lat[sub], sif_lon[sub], sif_data1.data[sub], sif_data2.data[sub]))\n",
    "\n",
    "\n",
    "        DG = pd.DataFrame(np.array(Each_Ref_Tile_Data),columns=['sounding_id','latitude','longitude','nrb1','nrb2'])\n",
    "        DG.to_csv('Optimization/{}_ref_{}.csv'.format(sif_date,shape2[0]),index=False)\n",
    "        print('\\n')\n",
    "        b  = tttt.time()\n",
    "        printmd('**{} minutes**'.format((b-a)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.to_csv('Optimization/{}_ref_{}.csv'.format(sif_date,shape),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
